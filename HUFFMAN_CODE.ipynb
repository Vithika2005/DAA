{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-docx PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 594600 bits\n",
      "Compressed size: 394279 bits\n",
      "Compression ratio: 0.66\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import os\n",
    "import collections\n",
    "from docx import Document  # For reading DOCX files\n",
    "import PyPDF2  # For reading PDF files\n",
    "\n",
    "# Node class for Huffman Tree\n",
    "class Node:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "# Function to build Huffman Tree\n",
    "def build_huffman_tree(frequency):\n",
    "    heap = [Node(char, freq) for char, freq in frequency.items()]\n",
    "    heapq.heapify(heap)\n",
    "    \n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        merged = Node(None, left.freq + right.freq)\n",
    "        merged.left = left\n",
    "        merged.right = right\n",
    "        heapq.heappush(heap, merged)\n",
    "        \n",
    "    return heap[0]\n",
    "\n",
    "# Function to generate Huffman Codes\n",
    "def generate_huffman_codes(root):\n",
    "    codes = {}\n",
    "    def _generate_codes(node, current_code):\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.char is not None:\n",
    "            codes[node.char] = current_code\n",
    "        _generate_codes(node.left, current_code + \"0\")\n",
    "        _generate_codes(node.right, current_code + \"1\")\n",
    "        \n",
    "    _generate_codes(root, \"\")\n",
    "    return codes\n",
    "\n",
    "# Function to compress content using Huffman Coding\n",
    "def compress(content):\n",
    "    frequency = collections.Counter(content)\n",
    "    huffman_tree_root = build_huffman_tree(frequency)\n",
    "    huffman_codes = generate_huffman_codes(huffman_tree_root)\n",
    "    \n",
    "    # Encode the content with Huffman codes\n",
    "    encoded_content = \"\".join(huffman_codes[char] for char in content)\n",
    "    \n",
    "    # Calculate the size of the original and compressed data\n",
    "    original_size = len(content) * 8  # 1 character = 8 bits\n",
    "    compressed_size = len(encoded_content)  # Compressed size in bits\n",
    "    \n",
    "    return encoded_content, huffman_codes, original_size, compressed_size\n",
    "\n",
    "# Function to calculate compression ratio\n",
    "def calculate_compression_ratio(original_size, compressed_size):\n",
    "    return compressed_size / original_size\n",
    "\n",
    "# Function to read TXT, HTML, DOCX, and PDF files\n",
    "def read_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    if ext in ['.txt', '.html']:  # Read as text files\n",
    "        encodings = ['utf-8', 'ISO-8859-1', 'windows-1252']\n",
    "        for enc in encodings:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding=enc) as file:\n",
    "                    return file.read()\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        raise UnicodeDecodeError(f\"Unable to decode file {file_path} with the available encodings.\")\n",
    "    \n",
    "    elif ext == '.docx':  # Read DOCX files using python-docx\n",
    "        doc = Document(file_path)\n",
    "        full_text = []\n",
    "        for para in doc.paragraphs:\n",
    "            full_text.append(para.text)\n",
    "        return '\\n'.join(full_text)\n",
    "    \n",
    "    elif ext == '.pdf':  # Read PDF files using PyPDF2\n",
    "        pdf_text = \"\"\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                pdf_text += page.extract_text()\n",
    "        return pdf_text\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "\n",
    "# Main function to compress file and compute compression ratio\n",
    "def huffman_compress_file(file_path):\n",
    "    try:\n",
    "        content = read_file(file_path)\n",
    "        compressed_data, codes, original_size, compressed_size = compress(content)\n",
    "        compression_ratio = calculate_compression_ratio(original_size, compressed_size)\n",
    "\n",
    "        # Save compressed data as binary string to a file\n",
    "        compressed_file_path = file_path + '.huffman'\n",
    "        with open(compressed_file_path, 'w') as f:\n",
    "            f.write(compressed_data)\n",
    "\n",
    "        print(f\"Original size: {original_size} bits\")\n",
    "        print(f\"Compressed size: {compressed_size} bits\")\n",
    "        print(f\"Compression ratio: {compression_ratio:.2f}\")\n",
    "\n",
    "        return compressed_file_path, compression_ratio\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(f\"Error: {fnf_error}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error: {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n",
    "# Example usage\n",
    "file_path = 'C:/Users/Vithika SURVE/Downloads/Prayer_programme_5c final one copy (2).html'  # Replace with your actual file path\n",
    "compressed_file, ratio = huffman_compress_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text: Prayer programme  â€“(Paras  to be excluded as he wont climb)  \n",
      "Please ask Prisha  if she is permitted\n",
      "Terminating program due to an unexpected error: Node() takes no arguments\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "from collections import defaultdict\n",
    "import PyPDF2\n",
    "import docx\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Node class for Huffman tree\n",
    "class Node:\n",
    "    def _init_(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def _lt_(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "# Huffman coding function\n",
    "def huffman_coding(data):\n",
    "    # Check for empty data\n",
    "    if not data:\n",
    "        raise ValueError(\"Error: No data provided for Huffman coding.\")\n",
    "\n",
    "    # Calculate frequency of each character\n",
    "    freq = defaultdict(int)\n",
    "    for char in data:\n",
    "        freq[char] += 1\n",
    "\n",
    "    # Build a priority queue\n",
    "    priority_queue = [Node(char, freq[char]) for char in freq]\n",
    "    heapq.heapify(priority_queue)\n",
    "\n",
    "    # Build the Huffman Tree\n",
    "    while len(priority_queue) > 1:\n",
    "        left = heapq.heappop(priority_queue)\n",
    "        right = heapq.heappop(priority_queue)\n",
    "        merged = Node(None, left.freq + right.freq)\n",
    "        merged.left = left\n",
    "        merged.right = right\n",
    "        heapq.heappush(priority_queue, merged)\n",
    "\n",
    "    # Generate Huffman codes\n",
    "    codes = {}\n",
    "    def generate_codes(node, current_code):\n",
    "        if node:\n",
    "            if node.char is not None:\n",
    "                codes[node.char] = current_code\n",
    "            generate_codes(node.left, current_code + \"0\")\n",
    "            generate_codes(node.right, current_code + \"1\")\n",
    "\n",
    "    generate_codes(priority_queue[0], \"\")\n",
    "    return codes\n",
    "\n",
    "# Function to read PDF files\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                extracted_text = page.extract_text()\n",
    "                if extracted_text:\n",
    "                    text += extracted_text + \"\\n\"\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Error: The PDF file is empty or contains no text.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {file_path}\")\n",
    "    except PyPDF2.PdfReadError:\n",
    "        raise ValueError(f\"Error: Unable to read PDF file: {file_path}\")\n",
    "    return text\n",
    "\n",
    "# Function to read DOC/DOCX files\n",
    "def read_doc(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Error: The DOC file is empty or contains no text.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {file_path}\")\n",
    "    except docx.opc.exceptions.PackageNotFoundError:\n",
    "        raise ValueError(f\"Error: The DOC file is corrupted or unreadable: {file_path}\")\n",
    "    return text\n",
    "\n",
    "# Function to read TXT files\n",
    "def read_txt(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Error: The TXT file is empty.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {file_path}\")\n",
    "    except UnicodeDecodeError:\n",
    "        raise ValueError(f\"Error: Unable to decode TXT file due to invalid encoding: {file_path}\")\n",
    "    return text\n",
    "\n",
    "# Function to read HTML files\n",
    "def read_html(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            text = soup.get_text()\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Error: The HTML file is empty or contains no text.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {file_path}\")\n",
    "    return text\n",
    "\n",
    "# Function to read file based on its extension\n",
    "def read_file(file_path):\n",
    "    if not file_path:\n",
    "        raise ValueError(\"Error: File path is empty.\")\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return read_pdf(file_path)\n",
    "    elif file_path.endswith('.doc') or file_path.endswith('.docx'):\n",
    "        return read_doc(file_path)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        return read_txt(file_path)\n",
    "    elif file_path.endswith('.html'):\n",
    "        return read_html(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Error: Unsupported file format: {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path='C:/Users/Vithika SURVE/OneDrive/Desktop/PYTHON PROJECTS/VITHIKA PYTHON/Prayer_programme_5c final one.pdf'  # Change to your file path\n",
    "\n",
    "try:\n",
    "    file_text = read_file(file_path)\n",
    "\n",
    "    if file_text:  # Proceed only if text was extracted\n",
    "        print(\"Extracted text:\", file_text[:100])  # Print first 100 characters\n",
    "\n",
    "        huffman_codes = huffman_coding(file_text)\n",
    "        print(\"Huffman Codes:\", huffman_codes)\n",
    "\n",
    "        # Calculate original and compressed sizes\n",
    "        original_size = len(file_text) * 8  # in bits\n",
    "        compressed_size = sum(len(code) * file_text.count(char) for char, code in huffman_codes.items())\n",
    "\n",
    "        print(f\"Original Size (in bits): {original_size}\")\n",
    "        print(f\"Compressed Size (in bits): {compressed_size}\")\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if compressed_size > 0:\n",
    "            compression_ratio = original_size / compressed_size\n",
    "        else:\n",
    "            compression_ratio = 0\n",
    "\n",
    "        print(f\"Compression Ratio: {compression_ratio:.2f}\")\n",
    "\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Terminating program: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Terminating program due to an unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'tuple' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 107\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file format.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m encoded_text, huffman_tree, compression_ratio \u001b[38;5;241m=\u001b[39m \u001b[43mhuffman_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m decoded_text \u001b[38;5;241m=\u001b[39m huffman_decoding(encoded_text, huffman_tree)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal text:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m, in \u001b[0;36mhuffman_encoding\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Build the Huffman tree\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(heap) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m     freq1, char1 \u001b[38;5;241m=\u001b[39m \u001b[43mheapq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheappop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     freq2, char2 \u001b[38;5;241m=\u001b[39m heapq\u001b[38;5;241m.\u001b[39mheappop(heap)\n\u001b[0;32m     29\u001b[0m     heapq\u001b[38;5;241m.\u001b[39mheappush(heap, (freq1 \u001b[38;5;241m+\u001b[39m freq2, (char1, char2)))\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'tuple' and 'str'"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "from bs4 import BeautifulSoup\n",
    "import docx\n",
    "import PyPDF2\n",
    "\n",
    "def huffman_encoding(text):\n",
    "    \"\"\"Encodes a text string using Huffman coding.\n",
    "\n",
    "    Args:\n",
    "        text: The input text string.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the encoded text, the Huffman tree, and the compression ratio.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count symbol frequencies\n",
    "    frequencies = {}\n",
    "    for char in text:\n",
    "        frequencies[char] = frequencies.get(char, 0) + 1\n",
    "\n",
    "    # Create a priority queue of symbols and their frequencies\n",
    "    heap = [(freq, char) for char, freq in frequencies.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    # Build the Huffman tree\n",
    "    while len(heap) > 1:\n",
    "        freq1, char1 = heapq.heappop(heap)\n",
    "        freq2, char2 = heapq.heappop(heap)\n",
    "        heapq.heappush(heap, (freq1 + freq2, (char1, char2)))\n",
    "\n",
    "    # Assign codewords to symbols\n",
    "    codewords = {}\n",
    "    def assign_codewords(node, code):\n",
    "        if isinstance(node, str):\n",
    "            codewords[node] = code\n",
    "        else:\n",
    "            assign_codewords(node[0], code + '0')\n",
    "            assign_codewords(node[1], code + '1')\n",
    "\n",
    "    assign_codewords(heap[0][1], '')\n",
    "\n",
    "    # Encode the text\n",
    "    encoded_text = ''.join(codewords[char] for char in text)\n",
    "\n",
    "    # Calculate compression ratio\n",
    "    original_size = len(text) * 8  # Assuming 8 bits per character\n",
    "    encoded_size = sum(len(codewords[char]) for char in text)\n",
    "    compression_ratio = encoded_size / original_size\n",
    "\n",
    "    return encoded_text, heap[0][1], compression_ratio\n",
    "\n",
    "def huffman_decoding(encoded_text, huffman_tree):\n",
    "    \"\"\"Decodes an encoded text string using a Huffman tree.\n",
    "\n",
    "    Args:\n",
    "        encoded_text: The encoded text string.\n",
    "        huffman_tree: The Huffman tree used for encoding.\n",
    "\n",
    "    Returns:\n",
    "        The decoded text string.\n",
    "    \"\"\"\n",
    "\n",
    "    decoded_text = ''\n",
    "    current_node = huffman_tree\n",
    "    for bit in encoded_text:\n",
    "        if bit == '0':\n",
    "            current_node = current_node[0]\n",
    "        else:\n",
    "            current_node = current_node[1]\n",
    "        if isinstance(current_node, str):\n",
    "            decoded_text += current_node\n",
    "            current_node = huffman_tree\n",
    "    return decoded_text\n",
    "\n",
    "# Example usage with HTML, DOC, and PDF\n",
    "def extract_text_from_html(html_file):\n",
    "    with open(html_file, 'r') as f:\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_doc(doc_file):\n",
    "    doc = docx.Document(doc_file)\n",
    "    text = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with open(pdf_file, 'rb') as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        text = ''\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Example usage with different file formats\n",
    "file_path = \"C:/Users/Vithika SURVE/Downloads/Prayer_programme_5c final one copy (2).html\"  # Replace with the actual file path\n",
    "if file_path.endswith(\".html\"):\n",
    "    text = extract_text_from_html(file_path)\n",
    "elif file_path.endswith(\".doc\"):\n",
    "    text = extract_text_from_doc(file_path)\n",
    "elif file_path.endswith(\".pdf\"):\n",
    "    text = extract_text_from_pdf(file_path)\n",
    "else:\n",
    "    print(\"Unsupported file format.\")\n",
    "\n",
    "encoded_text, huffman_tree, compression_ratio = huffman_encoding(text)\n",
    "decoded_text = huffman_decoding(encoded_text, huffman_tree)\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"Encoded text:\", encoded_text)\n",
    "print(\"Decoded text:\", decoded_text)\n",
    "print(\"Compression ratio:\", compression_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminating program: Error: Unsupported file format: C:/Users/Vithika SURVE/OneDrive/Desktop/PYTHON PROJECTS/VITHIKA PYTHON/Prayer_programme_5c final one.dox\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "from collections import defaultdict\n",
    "import PyPDF2\n",
    "import docx\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Node class for Huffman tree\n",
    "class Node:\n",
    "    def __init__(self, char, freq):  # Corrected constructor with double underscores\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):  # Corrected comparison method\n",
    "        return self.freq < other.freq\n",
    "\n",
    "# Huffman coding function\n",
    "def huffman_coding(data):\n",
    "    # Check for empty data\n",
    "    if not data:\n",
    "        raise ValueError(\"Error: No data provided for Huffman coding.\")\n",
    "\n",
    "    # Calculate frequency of each character\n",
    "    freq = defaultdict(int)\n",
    "    for char in data:\n",
    "        freq[char] += 1\n",
    "\n",
    "    # Build a priority queue\n",
    "    priority_queue = [Node(char, freq[char]) for char in freq]\n",
    "    heapq.heapify(priority_queue)\n",
    "\n",
    "    # Build the Huffman Tree\n",
    "    while len(priority_queue) > 1:\n",
    "        left = heapq.heappop(priority_queue)\n",
    "        right = heapq.heappop(priority_queue)\n",
    "        merged = Node(None, left.freq + right.freq)\n",
    "        merged.left = left\n",
    "        merged.right = right\n",
    "        heapq.heappush(priority_queue, merged)\n",
    "\n",
    "    # Generate Huffman codes\n",
    "    codes = {}\n",
    "    def generate_codes(node, current_code):\n",
    "        if node:\n",
    "            if node.char is not None:\n",
    "                codes[node.char] = current_code\n",
    "            generate_codes(node.left, current_code + \"0\")\n",
    "            generate_codes(node.right, current_code + \"1\")\n",
    "\n",
    "    generate_codes(priority_queue[0], \"\")\n",
    "    return codes\n",
    "\n",
    "# Function to read PDF files\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                extracted_text = page.extract_text()\n",
    "                if extracted_text:\n",
    "                    text += extracted_text + \"\\n\"\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Error: The PDF file is empty or contains no text.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {file_path}\")\n",
    "    except PyPDF2.PdfReadError:\n",
    "        raise ValueError(f\"Error: Unable to read PDF file: {file_path}\")\n",
    "    return text\n",
    "\n",
    "# Function to read DOC/DOCX files\n",
    "def read_doc(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Error: The DOC file is empty or contains no text.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {file_path}\")\n",
    "    except docx.opc.exceptions.PackageNotFoundError:\n",
    "        raise ValueError(f\"Error: The DOC file is corrupted or unreadable: {file_path}\")\n",
    "    return text\n",
    "\n",
    "# Function to read TXT files\n",
    "def read_txt(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Error: The TXT file is empty.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {file_path}\")\n",
    "    except UnicodeDecodeError:\n",
    "        raise ValueError(f\"Error: Unable to decode TXT file due to invalid encoding: {file_path}\")\n",
    "    return text\n",
    "\n",
    "# Function to read HTML files\n",
    "def read_html(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            text = soup.get_text()\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Error: The HTML file is empty or contains no text.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {file_path}\")\n",
    "    return text\n",
    "\n",
    "# Function to read file based on its extension\n",
    "def read_file(file_path):\n",
    "    if not file_path:\n",
    "        raise ValueError(\"Error: File path is empty.\")\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return read_pdf(file_path)\n",
    "    elif file_path.endswith('.doc') or file_path.endswith('.docx'):\n",
    "        return read_doc(file_path)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        return read_txt(file_path)\n",
    "    elif file_path.endswith('.html'):\n",
    "        return read_html(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Error: Unsupported file format: {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = 'C:/Users/Vithika SURVE/OneDrive/Desktop/PYTHON PROJECTS/VITHIKA PYTHON/Prayer_programme_5c final one.dox'  # Change to your file path\n",
    "\n",
    "try:\n",
    "    file_text = read_file(file_path)\n",
    "\n",
    "    if file_text:  # Proceed only if text was extracted\n",
    "        print(\"Extracted text:\", file_text[:100])  # Print first 100 characters\n",
    "\n",
    "        huffman_codes = huffman_coding(file_text)\n",
    "        print(\"Huffman Codes:\", huffman_codes)\n",
    "\n",
    "        # Calculate original and compressed sizes\n",
    "        original_size = len(file_text) * 8  # in bits\n",
    "        compressed_size = sum(len(code) * file_text.count(char) for char, code in huffman_codes.items())\n",
    "\n",
    "        print(f\"Original Size (in bits): {original_size}\")\n",
    "        print(f\"Compressed Size (in bits): {compressed_size}\")\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if compressed_size > 0:\n",
    "            compression_ratio = original_size / compressed_size\n",
    "        else:\n",
    "            compression_ratio = 0\n",
    "\n",
    "        print(f\"Compression Ratio: {compression_ratio:.2f}\")\n",
    "\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Terminating program: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Terminating program due to an unexpected error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
